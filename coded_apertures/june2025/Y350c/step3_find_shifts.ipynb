{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad77fab-e206-47c1-9655-088d14fe30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import cupyx.scipy.ndimage as ndimage\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# Use managed memory\n",
    "import h5py\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=f\".*peer.*\")\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils import *\n",
    "from rec import Rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fdd65-1cff-451e-865e-56cd8b7882a6",
   "metadata": {},
   "source": [
    "# Init data sizes and parametes of the PXM of ID16A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = f'Y350c_HT_015nm'\n",
    "path_out = f'/data/vnikitin/ESRF/ID16A/brain_rec/20240515/Y350c2'\n",
    "with h5py.File(f'{path_out}/{pfile}.h5') as fid:\n",
    "    detector_pixelsize = fid['/exchange/detector_pixelsize'][0]    \n",
    "    focusToDetectorDistance = fid['/exchange/focusdetectordistance'][0]    \n",
    "    z1 = fid['/exchange/z1'][:]        \n",
    "    theta = fid['/exchange/theta'][::step]\n",
    "    shifts = fid['/exchange/shifts'][::step]\n",
    "    attrs = fid['/exchange/attrs'][::step]\n",
    "    pos_shifts = fid['/exchange/pos_shifts'][::step]*1e-6\n",
    "    shape = fid['/exchange/data0'][::step].shape\n",
    "    shape_ref = fid['/exchange/data_white_start0'].shape\n",
    "    shape_dark = fid['/exchange/data_dark0'].shape\n",
    "    #pos_shifts-=pos_shifts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da169abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndist=4\n",
    "ntheta,n = shape[:2]\n",
    "ndark = shape_dark[0]\n",
    "nref = shape_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185647a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndist,ntheta,n)\n",
    "print(nref,ndark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa16f2-1f9c-4b3a-a330-e10942f12234",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = 33.35  # [keV] xray energy\n",
    "wavelength = 1.2398419840550367e-09/energy  # [m] wave length\n",
    "z2 = focusToDetectorDistance-z1\n",
    "distances = (z1*z2)/focusToDetectorDistance\n",
    "magnifications = focusToDetectorDistance/z1\n",
    "norm_magnifications = magnifications/magnifications[0]\n",
    "show = True\n",
    "\n",
    "energy = 33.35  # [keV] xray energy\n",
    "wavelength = 1.2398419840550367e-09/energy  # [m] wave length\n",
    "z2 = focusToDetectorDistance-z1\n",
    "magnifications = focusToDetectorDistance/z1\n",
    "norm_magnifications = magnifications/magnifications[0]\n",
    "distances = (z1*z2)/focusToDetectorDistance*norm_magnifications**2\n",
    "voxelsize = detector_pixelsize/magnifications[0]*2048/n  # object voxel size\n",
    "show = True\n",
    "\n",
    "pad = 0\n",
    "npsi = int(np.ceil((2048+2*pad)/norm_magnifications[-1]/16))*16  # make multiple of 8\n",
    "# npsi+=64\n",
    "rotation_axis=(879-(1616-npsi//2)//2+2.5)*n/1024#n/2#(796.25+2)*n/1024#397.5*2#499.75*n//1024+npsi//2-n//2\n",
    "\n",
    "print(rotation_axis)\n",
    "npsi//=(2048//n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace()\n",
    "args.ngpus = 4\n",
    "\n",
    "args.n = n\n",
    "args.ndist = ndist\n",
    "args.ntheta = ntheta\n",
    "args.pad = pad\n",
    "args.npsi = npsi\n",
    "args.nq = n + 2 * pad\n",
    "args.nchunk = 1\n",
    "args.voxelsize = voxelsize\n",
    "args.wavelength = wavelength\n",
    "args.distance = distances\n",
    "args.show = True\n",
    "args.norm_magnifications = norm_magnifications\n",
    "\n",
    "# create class\n",
    "cl_rec = Rec(args)\n",
    "\n",
    "# sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([ntheta,ndist,n,n],dtype='float32')\n",
    "with h5py.File(f'{path_out}/{pfile}_corr.h5') as fid:\n",
    "    for k in range(4):\n",
    "        data[:,k] = fid[f'/exchange/data{k}'][::step]\n",
    "    ref = fid[f'/exchange/ref'][:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeec07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = data/ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_random = np.zeros([ntheta,ndist,2],dtype='float32')\n",
    "for k in range(ndist):\n",
    "    shifts_random[:,k,0] = shifts[:,k,1]/norm_magnifications[k] \n",
    "    shifts_random[:,k,1] = shifts[:,k,0]/norm_magnifications[k] \n",
    "plt.plot(shifts_random[:,-1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdata = data/ref\n",
    "\n",
    "rdata_scaled = np.zeros([ntheta,ndist,args.n,args.n],dtype='float32')\n",
    "for j in np.arange(ndist)[::-1]:\n",
    "    tmp = cl_rec.STa(shifts_random[:,j]*norm_magnifications[j],rdata[:,j].astype('complex64'),'edge')    \n",
    "    tmp = (cl_rec.MT(tmp,j)/norm_magnifications[j]**2).real    \n",
    "    tmp=tmp[:,npsi//2-n//2:npsi//2+n//2,npsi//2-n//2:npsi//2+n//2]\n",
    "    rdata_scaled[:,j] = tmp\n",
    "    # for jj in range(ntheta):    \n",
    "    #     a = ndimage.zoom(cp.array(tmp[jj].real),1/norm_magnifications[j])        \n",
    "    #     rdata_scaled[jj,j] = a[a.shape[0]//2-n//2:a.shape[0]//2+n//2,a.shape[1]//2-n//2:a.shape[1]//2+n//2].get()\n",
    "        # print(jj,j,np.linalg.norm(rdata_scaled[jj,j]))\n",
    "    # tifffile.imwrite('/data/tmp/rr.tiff',tmp.real)\n",
    "    # break\n",
    "    # mshow(tmp[0],True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75042bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mshow_complex(rdata_scaled[0,0]+1j*rdata_scaled[0,1],True)#,vmax=1.5,vmin=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98629421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_shift(psi, p):\n",
    "    \"\"\"Apply shift for all projections.\"\"\"\n",
    "    psi = cp.array(psi)\n",
    "    p = cp.array(p)\n",
    "    tmp = cp.pad(psi,((0,0),(n//2,n//2),(n//2,n//2)), 'symmetric')\n",
    "    [x, y] = cp.meshgrid(cp.fft.rfftfreq(2*n),\n",
    "                         cp.fft.fftfreq(2*n))\n",
    "    shift = cp.exp(-2*cp.pi*1j *\n",
    "                   (x*p[:, 1, None, None]+y*p[:, 0, None, None]))\n",
    "    res0 = cp.fft.irfft2(shift*cp.fft.rfft2(tmp))\n",
    "    res = res0[:, n//2:3*n//2, n//2:3*n//2].get()\n",
    "    return res\n",
    "\n",
    "def _upsampled_dft(data, ups,\n",
    "                   upsample_factor=1, axis_offsets=None):\n",
    "\n",
    "    im2pi = 1j * 2 * cp.pi\n",
    "    tdata = data.copy()\n",
    "    kernel = (cp.tile(cp.arange(ups), (data.shape[0], 1))-axis_offsets[:, 1:2])[\n",
    "        :, :, None]*cp.fft.fftfreq(data.shape[2], upsample_factor)\n",
    "    kernel = cp.exp(-im2pi * kernel)\n",
    "    tdata = cp.einsum('ijk,ipk->ijp', kernel, tdata)\n",
    "    kernel = (cp.tile(cp.arange(ups), (data.shape[0], 1))-axis_offsets[:, 0:1])[\n",
    "        :, :, None]*cp.fft.fftfreq(data.shape[1], upsample_factor)\n",
    "    kernel = cp.exp(-im2pi * kernel)\n",
    "    rec = cp.einsum('ijk,ipk->ijp', kernel, tdata)\n",
    "\n",
    "    return rec\n",
    "\n",
    "def registration_shift(src_image, target_image, upsample_factor=1, space=\"real\"):\n",
    "    # print(src_image.shape)\n",
    "    src_image=cp.array(src_image)\n",
    "    target_image=cp.array(target_image)\n",
    "    # assume complex data is already in Fourier space\n",
    "    if space.lower() == 'fourier':\n",
    "        src_freq = src_image\n",
    "        target_freq = target_image\n",
    "    # real data needs to be fft'd.\n",
    "    elif space.lower() == 'real':\n",
    "        src_freq = cp.fft.fft2(src_image)\n",
    "        target_freq = cp.fft.fft2(target_image)\n",
    "\n",
    "    # Whole-pixel shift - Compute cross-correlation by an IFFT\n",
    "    shape = src_freq.shape\n",
    "    image_product = src_freq * target_freq.conj()\n",
    "    cross_correlation = cp.fft.ifft2(image_product)\n",
    "    A = cp.abs(cross_correlation)\n",
    "    maxima = A.reshape(A.shape[0], -1).argmax(1)\n",
    "    maxima = cp.column_stack(cp.unravel_index(maxima, A[0, :, :].shape))\n",
    "\n",
    "    midpoints = cp.array([cp.fix(axis_size / 2)\n",
    "                          for axis_size in shape[1:]])\n",
    "\n",
    "    shifts = cp.array(maxima, dtype=cp.float64)\n",
    "    ids = cp.where(shifts[:, 0] > midpoints[0])\n",
    "    shifts[ids[0], 0] -= shape[1]\n",
    "    ids = cp.where(shifts[:, 1] > midpoints[1])\n",
    "    shifts[ids[0], 1] -= shape[2]\n",
    "    \n",
    "    if upsample_factor > 1:\n",
    "        # Initial shift estimate in upsampled grid\n",
    "        shifts = cp.round(shifts * upsample_factor) / upsample_factor\n",
    "        upsampled_region_size = cp.ceil(upsample_factor * 1.5)\n",
    "        # Center of output array at dftshift + 1\n",
    "        dftshift = cp.fix(upsampled_region_size / 2.0)\n",
    "\n",
    "        normalization = (src_freq[0].size * upsample_factor ** 2)\n",
    "        # Matrix multiply DFT around the current shift estimate\n",
    "\n",
    "        sample_region_offset = dftshift - shifts*upsample_factor\n",
    "        cross_correlation = _upsampled_dft(image_product.conj(),\n",
    "                                                upsampled_region_size,\n",
    "                                                upsample_factor,\n",
    "                                                sample_region_offset).conj()\n",
    "        cross_correlation /= normalization\n",
    "        # Locate maximum and map back to original pixel grid\n",
    "        A = cp.abs(cross_correlation)\n",
    "        maxima = A.reshape(A.shape[0], -1).argmax(1)\n",
    "        maxima = cp.column_stack(\n",
    "            cp.unravel_index(maxima, A[0, :, :].shape))\n",
    "\n",
    "        maxima = cp.array(maxima, dtype=cp.float64) - dftshift\n",
    "\n",
    "        shifts = shifts + maxima / upsample_factor\n",
    "           \n",
    "    return shifts.get()\n",
    "\n",
    "rdata_scaled_shifted = rdata_scaled.copy()\n",
    "for j in range(100):\n",
    "    for k in range(ndist):\n",
    "        mstep = 3000//100//step\n",
    "        shifts[j*mstep:j*mstep+mstep,k] = registration_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],rdata_scaled[j*mstep:j*mstep+mstep,0],upsample_factor=1000)\n",
    "        rdata_scaled_shifted[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],-shifts[j*mstep:j*mstep+mstep,k]-shifts_random[j*mstep:j*mstep+mstep,k])\n",
    "# write_tiff(rdata_scaled[:,0],'/data/tmp/rdata_scaled_shifted_check0',overwrite=True)\n",
    "# write_tiff(rdata_scaled[:,2],'/data/tmp/rdata_scaled_shifted_check2',overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_m=np.tile(np.median(shifts,axis=0),(ntheta,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "pshifts = scipy.io.loadmat('/data/vnikitin/ESRF/ID16A/brain/20240515/Y350c/Y350c_HT_015nm_/rhapp_fixed.mat')['pshifts'][0,0][0]\n",
    "pshifts=-pshifts.swapaxes(0,2)[:3000:step]\n",
    "\n",
    "for k in range(1,4):\n",
    "    plt.plot(pshifts[:,k,1])\n",
    "    plt.plot(shifts_m[:,k,1])\n",
    "    plt.plot(pshifts[:,k,0])\n",
    "    plt.plot(shifts_m[:,k,0])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = shifts_m+shifts_random\n",
    "# shifts = cp.array(pshifts)+cp.array(shifts_random)\n",
    "# rdata_scaled_shifted_check=rdata_scaled.copy()\n",
    "# for j in range(100):\n",
    "#     for k in range(ndist):\n",
    "#         mstep = 3000//100//step\n",
    "#         # shifts[j*mstep:j*mstep+mstep,k] = registration_shift(rdata_scaled_shifted[j*mstep:j*mstep+mstep,k],rdata_scaled_shifted[j*mstep:j*mstep+mstep,0],upsample_factor=1000)\n",
    "#         rdata_scaled_shifted_check[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],-shifts[j*mstep:j*mstep+mstep,k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(ndist):\n",
    "#     mshow_complex(rdata_scaled_shifted[0,k]+1j*rdata_scaled_shifted[0,0],show)\n",
    "#     mshow_complex(rdata_scaled_shifted_check[0,k]+1j*rdata_scaled_shifted_check[0,0],show)\n",
    "#     mshow_complex(rdata_scaled_shifted[0,k]-rdata_scaled_shifted[0,0]+1j*(rdata_scaled_shifted_check[0,k]-rdata_scaled_shifted_check[0,0]),show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = np.loadtxt('/data/vnikitin/ESRF/ID16A/brain/20240515/Y350c/Y350c_HT_015nm_/correct_correct3D.txt')[:3000:step][:,::-1]\n",
    "\n",
    "# plt.plot(s[:,1])\n",
    "# plt.plot(s[:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rdata_scaled_shifted_check3d = rdata_scaled_shifted_check[:,0].copy()\n",
    "# for j in range(100):\n",
    "#     mstep = 3000//100//step\n",
    "#     rdata_scaled_shifted_check3d[j*mstep:j*mstep+mstep] = apply_shift(rdata_scaled_shifted_check3d[j*mstep:j*mstep+mstep],-s[j*mstep:j*mstep+mstep])\n",
    "#     # mshow_complex(rdata_scaled[0,k]-rdata_scaled[1,k]+1j*(rdata_scaled_shifted[0,k]-rdata_scaled_shifted[1,k]),show)\n",
    "# write_tiff(rdata_scaled_shifted_check3d[:],'/data/tmp/rdata_scaled_shifted_check3d',overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifts_final = shifts.get()+s[:,np.newaxis]\n",
    "# final = rdata_scaled.copy()\n",
    "# for j in range(100):\n",
    "#     for k in range(ndist):\n",
    "#         mstep = 3000//100//step\n",
    "#         final[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],-shifts_final[j*mstep:j*mstep+mstep,k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{path_out}/{pfile}_corr.h5','a') as fid:\n",
    "    try:\n",
    "        del fid[f'/exchange/cshifts_final']\n",
    "    except:\n",
    "        pass\n",
    "    fid.create_dataset(f'/exchange/cshifts_final',data = shifts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holotomocupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
