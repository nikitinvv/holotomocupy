{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import write_tiff, read_tiff\n",
    "from utils import mshow, mshow_polar, mshow_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2048  # data size in each dimension\n",
    "nobj = 4096+4096#n+n//4+n//8 # object size in each dimension\n",
    "pad = n//16 # pad for the reconstructed probe\n",
    "nprb = n+2*pad # probe size\n",
    "extra = 8 # extra padding for shifts\n",
    "npatch = nprb+2*extra # patch size for shifts\n",
    "\n",
    "npos = 16 # total number of positions\n",
    "z1 = -17.75e-3# [m] position of the sample\n",
    "detector_pixelsize = 3.03751e-6\n",
    "energy = 33.35  # [keV] xray energy\n",
    "wavelength = 1.24e-09/energy  # [m] wave length\n",
    "focusToDetectorDistance = 1.28  # [m]\n",
    "# adjustments for the cone beam\n",
    "z2 = focusToDetectorDistance-z1\n",
    "distance = (z1*z2)/focusToDetectorDistance\n",
    "magnification = focusToDetectorDistance/z1\n",
    "voxelsize = float(cp.abs(detector_pixelsize/magnification))\n",
    "\n",
    "show = True # do visualization or not at all\n",
    "\n",
    "path = f'/data/vnikitin/ESRF/ID16A/20240924/SiemensLH/code2um_nfp18x18_01'\n",
    "path_out = f'/data/vnikitin/ESRF/ID16A/20240924_rec2/SiemensLH/code2um_nfp18x18_01'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresnel kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = cp.fft.fftfreq(nprb, d=voxelsize)#.astype('float32')\n",
    "[fx, fy] = cp.meshgrid(fx, fx)\n",
    "fker = cp.exp(-1j*cp.pi*wavelength*distance*(fx**2+fy**2))\n",
    "mshow_complex(cp.fft.fftshift(fker),mshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Lop(psi):   \n",
    "    \"\"\"Forward propagator\"\"\" \n",
    "\n",
    "    # convolution\n",
    "    # ff = cp.pad(psi,((0,0),(nprb//2,nprb//2),(nprb//2,nprb//2)))\n",
    "    ff = psi\n",
    "    ff = cp.fft.ifft2(cp.fft.fft2(ff)*fker)    \n",
    "    # ff = ff[:,nprb//2:-nprb//2,nprb//2:-nprb//2]\n",
    "    \n",
    "    # crop to detector size\n",
    "    ff = ff[:,pad:nprb-pad,pad:nprb-pad]\n",
    "    return ff\n",
    "\n",
    "def LTop(psi):\n",
    "    \"\"\"Adjoint propagator\"\"\" \n",
    "\n",
    "    # pad to the probe size\n",
    "    ff = cp.pad(psi,((0,0),(pad,pad),(pad,pad)))    \n",
    "    \n",
    "    # convolution\n",
    "    # ff = cp.pad(ff,((0,0),(nprb//2,nprb//2),(nprb//2,nprb//2)))    \n",
    "    ff = cp.fft.ifft2(cp.fft.fft2(ff)/fker)\n",
    "    # ff = ff[:,nprb//2:-nprb//2,nprb//2:-nprb//2]\n",
    "    return ff\n",
    "\n",
    "def Ex(psi,ix):\n",
    "    \"\"\"Extract patches\"\"\"\n",
    "\n",
    "    res = cp.empty([ix.shape[0],npatch,npatch],dtype='complex64')\n",
    "    stx = nobj//2-ix[:,1]-npatch//2\n",
    "    endx = stx+npatch\n",
    "    sty = nobj//2-ix[:,0]-npatch//2\n",
    "    endy = sty+npatch\n",
    "    for k in range(len(stx)):\n",
    "        res[k] = psi[sty[k]:endy[k],stx[k]:endx[k]]     \n",
    "    return res\n",
    "\n",
    "def ExT(psi,psir,ix):\n",
    "    \"\"\"Adjoint extract patches\"\"\"\n",
    "\n",
    "    stx = nobj//2-ix[:,1]-npatch//2\n",
    "    endx = stx+npatch\n",
    "    sty = nobj//2-ix[:,0]-npatch//2\n",
    "    endy = sty+npatch\n",
    "    for k in range(len(stx)):\n",
    "        psi[sty[k]:endy[k],stx[k]:endx[k]] += psir[k]\n",
    "    return psi\n",
    "\n",
    "def S(psi,p):\n",
    "    \"\"\"Subpixel shift\"\"\"\n",
    "\n",
    "    x = cp.fft.fftfreq(npatch).astype('float32')\n",
    "    [y, x] = cp.meshgrid(x, x)\n",
    "    pp = cp.exp(-2*cp.pi*1j * (y*p[:, 1, None, None]+x*p[:, 0, None, None])).astype('complex64')\n",
    "    res = cp.fft.ifft2(pp*cp.fft.fft2(psi))\n",
    "    return res\n",
    "\n",
    "def Sop(psi,ix,x,ex):\n",
    "    \"\"\"Extract patches with subpixel shift\"\"\"\n",
    "    data = cp.zeros([x.shape[1], nprb, nprb], dtype='complex64')\n",
    "    psir = Ex(psi,ix)     \n",
    "    psir = S(psir,x)\n",
    "    data = psir[:, ex:npatch-ex, ex:npatch-ex]\n",
    "    return data\n",
    "\n",
    "def STop(d,ix,x,ex):\n",
    "    \"\"\"Adjont extract patches with subpixel shift\"\"\"\n",
    "    psi = cp.zeros([nobj, nobj], dtype='complex64')\n",
    "    dr = cp.pad(d, ((0, 0), (ex, ex), (ex, ex)))\n",
    "    dr = S(dr,-x)        \n",
    "    ExT(psi,dr,ix)\n",
    "    return psi\n",
    "# # adjoint tests\n",
    "# shifts_test = 30*(cp.random.random([npos,2])-0.5).astype('float32')\n",
    "# ishifts = shifts_test.astype('int32')\n",
    "# fshifts = shifts_test-ishifts\n",
    "\n",
    "# arr1 = (cp.random.random([nobj,nobj])+1j*cp.random.random([nobj,nobj])).astype('complex64')\n",
    "# arr2 = Ex(arr1,ishifts)\n",
    "# arr3 = arr1*0\n",
    "# ExT(arr3,arr2,ishifts)\n",
    "# print(f'{cp.sum(arr1*cp.conj(arr3))}==\\n{cp.sum(arr2*cp.conj(arr2))}')\n",
    "\n",
    "# arr1 = (cp.random.random([nobj,nobj])+1j*cp.random.random([nobj,nobj])).astype('complex64')\n",
    "# arr2 = Sop(arr1,ishifts,fshifts,extra)\n",
    "# arr3 = STop(arr2,ishifts,fshifts,extra)\n",
    "# print(f'{cp.sum(arr1*cp.conj(arr3))}==\\n{cp.sum(arr2*cp.conj(arr2))}')\n",
    "\n",
    "# arr1 = (cp.random.random([npos,nprb,nprb])+1j*cp.random.random([npos,nprb,nprb])).astype('complex64')\n",
    "# arr2 = Lop(arr1)\n",
    "# arr3 = LTop(arr2)\n",
    "# print(f'{cp.sum(arr1*cp.conj(arr3))}==\\n{cp.sum(arr2*cp.conj(arr2))}')\n",
    "# arr1=arr2=arr3=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "npos = 18*18\n",
    "pos_step = 1 # steps in positions\n",
    "with h5py.File(f'{path}/code2um_nfp18x18_010000.h5') as fid:\n",
    "    data = fid['/entry_0000/measurement/data'][:npos].astype('float32')\n",
    "    \n",
    "with h5py.File(f'{path}/ref_0000.h5') as fid:\n",
    "    ref = fid['/entry_0000/measurement/data'][:].astype('float32')\n",
    "with h5py.File(f'{path}/dark_0000.h5') as fid:\n",
    "    dark = fid['/entry_0000/measurement/data'][:].astype('float32')\n",
    "\n",
    "shifts = np.loadtxt(f'/data/vnikitin/ESRF/ID16A/20240924/positions/shifts_code_nfp18x18ordered.txt')[:,::-1]\n",
    "shifts = shifts/voxelsize*(2048//n)*1e-6\n",
    "shifts[:,1]*=-1\n",
    "\n",
    "print(shifts[-10:])\n",
    "shifts = np.load(f'shifts_new.npy')\n",
    "print(shifts[-10:])\n",
    "#centering\n",
    "shifts[:,1]-=(np.amax(shifts[:,1])+np.amin(shifts[:,1]))/2\n",
    "shifts[:,0]-=(np.amax(shifts[:,0])+np.amin(shifts[:,0]))/2\n",
    "shifts = shifts.reshape(int(np.sqrt(npos)),int(np.sqrt(npos)),2)\n",
    "shifts = shifts[::pos_step,::pos_step,:].reshape(npos//pos_step**2,2)\n",
    "data = data.reshape(int(np.sqrt(npos)),int(np.sqrt(npos)),n,n)\n",
    "data = data[::pos_step,::pos_step,:].reshape(npos//pos_step**2,n,n)\n",
    "\n",
    "ids = np.where((np.abs(shifts[:,0])<nobj//2-n//2-pad-extra)*(np.abs(shifts[:,1])<nobj//2-n//2-pad-extra))[0]#[0:2]\n",
    "data = data[ids]\n",
    "shifts = shifts[ids]\n",
    "\n",
    "plt.plot(shifts[:,0],shifts[:,1],'.')\n",
    "plt.axis('square')\n",
    "plt.show()\n",
    "\n",
    "npos = len(ids)\n",
    "print(f'{npos=}')\n",
    "\n",
    "chunk = 16\n",
    "nchunk = int(np.ceil(npos/chunk))\n",
    "\n",
    "#data=cp.array(data)\n",
    "#dark=cp.array(dark)\n",
    "#ref=cp.array(ref)\n",
    "#shifts=cp.array(shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupyx.scipy.ndimage as ndimage\n",
    "def remove_outliers(data, dezinger, dezinger_threshold):    \n",
    "    res = data.copy()\n",
    "    w = [dezinger,dezinger]\n",
    "    for k in range(data.shape[0]):\n",
    "        data0 = cp.array(data[k])\n",
    "        fdata = ndimage.median_filter(data0, w)\n",
    "        print(np.sum(np.abs(data0-fdata)>fdata*dezinger_threshold))\n",
    "        res[k] = np.where(np.abs(data0-fdata)>fdata*dezinger_threshold, fdata, data0).get()\n",
    "    return res\n",
    "\n",
    "dark = np.mean(dark,axis=0)\n",
    "ref = np.mean(ref,axis=0)\n",
    "data -= dark\n",
    "ref -= dark\n",
    "\n",
    "data[data<0]=0\n",
    "ref[ref<0]=0\n",
    "data[:,1320//3:1320//3+25//3,890//3:890//3+25//3] = data[:,1280//3:1280//3+25//3,890//3:890//3+25//3]\n",
    "ref[1320//3:1320//3+25//3,890//3:890//3+25//3] = ref[1280//3:1280//3+25//3,890//3:890//3+25//3]\n",
    "\n",
    "data = remove_outliers(data, 3, 0.8)    \n",
    "ref = remove_outliers(ref[None], 3, 0.8)[0]\n",
    "\n",
    "data /= np.mean(ref)\n",
    "ref /= np.mean(ref)\n",
    "\n",
    "data[np.isnan(data)] = 1\n",
    "ref[np.isnan(ref)] = 1\n",
    "\n",
    "mshow(data[0],mshow)\n",
    "mshow(ref,mshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paganin reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Paganin(data, wavelength, voxelsize, delta_beta,  alpha):\n",
    "    fx = cp.fft.fftfreq(data.shape[-1], d=voxelsize).astype('float32')\n",
    "    [fx, fy] = cp.meshgrid(fx, fx)\n",
    "    rad_freq = cp.fft.fft2(data)\n",
    "    taylorExp = 1 + wavelength * distance * cp.pi * (delta_beta) * (fx**2+fy**2)\n",
    "    numerator = taylorExp * (rad_freq)\n",
    "    denominator = taylorExp**2 + alpha\n",
    "    phase = cp.log(cp.real(cp.fft.ifft2(numerator / denominator)))\n",
    "    phase = delta_beta * 0.5 * phase\n",
    "    return phase\n",
    "\n",
    "def rec_init(rdata,ishifts):\n",
    "    recMultiPaganin = cp.zeros([nobj,nobj],dtype='float32')\n",
    "    recMultiPaganinr = cp.zeros([nobj,nobj],dtype='float32')# to compensate for overlap\n",
    "    for j in range(0,npos):\n",
    "        r = cp.array(rdata[j])        \n",
    "        r = Paganin(r, wavelength, voxelsize,  24.05, 1e-1)\n",
    "        rr = r*0+1 # to compensate for overlap                        \n",
    "        rpsi = cp.zeros([nobj,nobj],dtype='float32')\n",
    "        rrpsi = cp.zeros([nobj,nobj],dtype='float32')\n",
    "        stx = nobj//2-ishifts[j,1]-n//2\n",
    "        endx = stx+n\n",
    "        sty = nobj//2-ishifts[j,0]-n//2\n",
    "        endy = sty+n\n",
    "        rpsi[sty:endy,stx:endx] = r\n",
    "        rrpsi[sty:endy,stx:endx] = rr\n",
    "        \n",
    "        recMultiPaganin += rpsi\n",
    "        recMultiPaganinr += rrpsi\n",
    "        \n",
    "    recMultiPaganinr[np.abs(recMultiPaganinr)<5e-2] = 1    \n",
    "    recMultiPaganin /= recMultiPaganinr    \n",
    "    recMultiPaganin = np.exp(1j*recMultiPaganin)\n",
    "    return recMultiPaganin\n",
    "\n",
    "ishifts = np.round(np.array(shifts)).astype('int32')\n",
    "rdata = np.array(data/(ref+1e-5))\n",
    "rec_paganin = rec_init(rdata,ishifts)\n",
    "mshow_polar(rec_paganin,show)\n",
    "mshow_polar(rec_paganin[:1000,:1000],show)\n",
    "\n",
    "# smooth borders\n",
    "v = cp.arange(-nobj//2, nobj//2)/nobj\n",
    "[vx, vy] = cp.meshgrid(v, v)\n",
    "v = cp.exp(-1000*(vx**2+vy**2)).astype('float32')\n",
    "\n",
    "rec_paganin = cp.fft.fftshift(cp.fft.fftn(cp.fft.fftshift(rec_paganin)))\n",
    "rec_paganin = cp.fft.fftshift(cp.fft.ifftn(cp.fft.fftshift(rec_paganin*v))).astype('complex64')\n",
    "mshow_polar(rec_paganin,show)\n",
    "mshow_polar(rec_paganin[:1000,:1000],show)\n",
    "\n",
    "rdata=v=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientF0(pars, reused, d, st, end):\n",
    "    d = cp.array(d[st:end])\n",
    "\n",
    "    Lpsi =  cp.array(reused['Lpsi'][st:end]    )\n",
    "    if pars['model']=='Gaussian':\n",
    "        td = d*(Lpsi/(cp.abs(Lpsi)+pars['eps']))                \n",
    "        res = 2*LTop(Lpsi - td)        \n",
    "    elif pars['model']=='Poisson':\n",
    "        dd = d*Lpsi/(cp.abs(Lpsi)**2+pars['eps']**2) \n",
    "        res = 2*LTop(Lpsi-dd)  \n",
    "    reused['gradF'][st:end] = res.get()    \n",
    "\n",
    "def gradientF(pars, reused, d):\n",
    "    reused['gradF'] = np.zeros([npos,nprb,nprb],dtype='complex64')\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        gradientF0(pars, reused, d, st, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_psi0(psi, q,ix,x,ex,gradF,st,end):\n",
    "    x = cp.array(x[st:end])\n",
    "    ix = cp.array(ix[st:end])\n",
    "    gradF = cp.array(gradF[st:end])\n",
    "    d = cp.conj(q)*gradF\n",
    "    dr = cp.pad(d, ((0, 0), (ex, ex), (ex, ex)))\n",
    "    dr = S(dr,-x)        \n",
    "    ExT(psi,dr,ix)\n",
    "\n",
    "def gradient_psi(q,ix,x,ex,gradF):\n",
    "    psi = cp.zeros([nobj, nobj], dtype='complex64')\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        gradient_psi0(psi, q,ix,x,ex,gradF,st,end)    \n",
    "    return psi\n",
    "\n",
    "def gradient_prb0(spsi,gradF,st,end):\n",
    "    spsi = cp.array(spsi[st:end])\n",
    "    gradF = cp.array(gradF[st:end])\n",
    "    return cp.sum(cp.conj(spsi)*gradF,axis=0)\n",
    "\n",
    "def gradient_prb(spsi,gradF):\n",
    "    res = cp.zeros([nprb,nprb],dtype='complex64')\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        res += gradient_prb0(spsi,gradF,st,end)\n",
    "    return res\n",
    "\n",
    "def gradient_shift0(psi, q, ix, x, ex, gradF, st, end):    \n",
    "    ix = cp.array(ix[st:end])\n",
    "    x = cp.array(x[st:end])\n",
    "    gradF = cp.array(gradF[st:end])\n",
    "    # frequencies\n",
    "    xi1 = cp.fft.fftfreq(npatch).astype('float32')\n",
    "    xi2, xi1 = cp.meshgrid(xi1, xi1)\n",
    "\n",
    "    # multipliers in frequencies\n",
    "    w = cp.exp(-2 * cp.pi * 1j * (xi2 * x[:, 1, None, None] + xi1 * x[:, 0, None, None]))\n",
    "    \n",
    "    # Gradient parts\n",
    "    tmp = Ex(psi, ix)\n",
    "    tmp = cp.fft.fft2(tmp) \n",
    "\n",
    "    dt1 = cp.fft.ifft2(w*xi1*tmp)\n",
    "    dt2 = cp.fft.ifft2(w*xi2*tmp)\n",
    "    dt1 = -2 * cp.pi * dt1[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    dt2 = -2 * cp.pi * dt2[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    \n",
    "    # inner product with gradF\n",
    "    gradx = cp.zeros([gradF.shape[0], 2], dtype='float32')\n",
    "    gradx[:,0] = imdot(gradF, q * dt1, axis=(1, 2))\n",
    "    gradx[:,1] = imdot(gradF, q * dt2, axis=(1, 2))\n",
    "    return gradx.get()\n",
    "\n",
    "def gradient_shift(psi, q, ix, x, ex, gradF):    \n",
    "    gradx = np.zeros([npos, 2], dtype='float32')\n",
    "    for k in range(nchunk):\n",
    "        st = k*chunk\n",
    "        end = min((k+1)*chunk,npos)\n",
    "        gradx[st:end] = gradient_shift0(psi, q, ix, x, ex, gradF, st, end)    \n",
    "    return gradx\n",
    "\n",
    "\n",
    "def gradients(vars,pars,reused):    \n",
    "    (q,psi,x) = (vars['prb'], vars['psi'], vars['fshift'])\n",
    "    (ix,ex,rho) = (pars['ishift'],pars['extra'],pars['rho'])\n",
    "    (gradF, spsi) = (reused['gradF'],reused['spsi'])\n",
    "    dpsi = gradient_psi(q,ix,x,ex,gradF)\n",
    "    dprb = gradient_prb(spsi,gradF)\n",
    "    dx = gradient_shift(psi,q,ix,x,ex,gradF)\n",
    "    grads={'psi': rho[0]*dpsi, 'prb': rho[1]*dprb, 'fshift': rho[2]*dx}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessianF(Lm,Ldm1,Ldm2,data,pars):\n",
    "    if pars['model']=='Gaussian':\n",
    "        psi0p = Lm/(cp.abs(Lm)+pars['eps'])\n",
    "        d0 = data/(cp.abs(Lm)+pars['eps'])\n",
    "        v1 = cp.sum((1-d0)*reprod(Ldm1,Ldm2))\n",
    "        v2 = cp.sum(d0*reprod(psi0p,Ldm1)*reprod(psi0p,Ldm2))        \n",
    "    else:        \n",
    "        psi0p = Lm/(cp.abs(Lm)+pars['eps'])            \n",
    "        v1 = cp.sum((1-data/(cp.abs(Lm)**2+pars['eps']**2))*reprod(Ldm1,Ldm2))\n",
    "        v2 = 2*cp.sum(data*reprod(psi0p,Ldm1)*reprod(psi0p,Ldm2)/(cp.abs(Lm)**2+pars['eps']**2))\n",
    "    return 2*(v1+v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized version, without extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_beta0(vars,grads,etas,pars,reused,d,st,end):\n",
    "    (q,psi,x) = (vars['prb'], vars['psi'], vars['fshift'][st:end])    \n",
    "    (ix,ex,rho) = (pars['ishift'][st:end],pars['extra'],pars['rho'])\n",
    "    (spsi,Lpsi,gradF) = (reused['spsi'][st:end], reused['Lpsi'][st:end], reused['gradF'][st:end])\n",
    "    x = cp.array(x)\n",
    "    ix = cp.array(ix)\n",
    "    spsi = cp.array(spsi)\n",
    "    Lpsi = cp.array(Lpsi)\n",
    "    gradF = cp.array(gradF)\n",
    "    d = cp.array(d[st:end])\n",
    "\n",
    "    # note scaling with rho\n",
    "    (dpsi1,dq1,dx1) = (grads['psi']*rho[0], grads['prb']*rho[1], grads['fshift'][st:end]*rho[2])\n",
    "    (dpsi2,dq2,dx2) = (etas['psi']*rho[0], etas['prb']*rho[1], etas['fshift'][st:end]*rho[2])\n",
    "    dx1 = cp.array(dx1)\n",
    "    dx2 = cp.array(dx2)\n",
    "        \n",
    "    # frequencies\n",
    "    xi1 = cp.fft.fftfreq(npatch).astype('float32')\n",
    "    [xi2, xi1] = cp.meshgrid(xi1, xi1)    \n",
    "\n",
    "    # multipliers in frequencies\n",
    "    dx1 = dx1[:,:,cp.newaxis,cp.newaxis]\n",
    "    dx2 = dx2[:,:,cp.newaxis,cp.newaxis]\n",
    "    w = cp.exp(-2*cp.pi*1j * (xi2*x[:, 1, None, None]+xi1*x[:, 0, None, None]))\n",
    "    w1 = xi1*dx1[:,0]+xi2*dx1[:,1]\n",
    "    w2 = xi1*dx2[:,0]+xi2*dx2[:,1]\n",
    "    w12 = xi1**2*dx1[:,0]*dx2[:,0]+ \\\n",
    "                xi1*xi2*(dx1[:,0]*dx2[:,1]+dx1[:,1]*dx2[:,0])+ \\\n",
    "                xi2**2*dx1[:,1]*dx2[:,1]\n",
    "    w22 = xi1**2*dx2[:,0]**2+ 2*xi1*xi2*(dx2[:,0]*dx2[:,1]) + xi2**2*dx2[:,1]**2\n",
    "    \n",
    "    # DT, D2T terms\n",
    "    tmp1 = Ex(dpsi1,ix)     \n",
    "    tmp1 = cp.fft.fft2(tmp1)\n",
    "    sdpsi1 = cp.fft.ifft2(w*tmp1)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    dt12 = -2*cp.pi*1j*cp.fft.ifft2(w*w2*tmp1)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    \n",
    "    tmp2 = Ex(dpsi2,ix)     \n",
    "    tmp2 = cp.fft.fft2(tmp2)\n",
    "    sdpsi2 = cp.fft.ifft2(w*tmp2)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    dt21 = -2*cp.pi*1j*cp.fft.ifft2(w*w1*tmp2)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    dt22 = -2*cp.pi*1j*cp.fft.ifft2(w*w2*tmp2)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    \n",
    "    tmp = Ex(psi,ix)     \n",
    "    tmp = cp.fft.fft2(tmp)        \n",
    "    dt1 = -2*cp.pi*1j*cp.fft.ifft2(w*w1*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    dt2 = -2*cp.pi*1j*cp.fft.ifft2(w*w2*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    d2t1 = -4*cp.pi**2*cp.fft.ifft2(w*w12*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    d2t2 = -4*cp.pi**2*cp.fft.ifft2(w*w22*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    \n",
    "    # DM,D2M terms\n",
    "    d2m1 =  q*dt12 + q*dt21 + q*d2t1\n",
    "    d2m1 += dq1*sdpsi2 + dq2*sdpsi1\n",
    "    d2m1 += dq1*dt2 + dq2*dt1\n",
    "\n",
    "    d2m2 =  q*dt22 + q*dt22 + q*d2t2\n",
    "    d2m2 += dq2*sdpsi2 + dq2*sdpsi2\n",
    "    d2m2 += dq2*dt2 + dq2*dt2\n",
    "\n",
    "    dm1 = dq1*spsi+q*(sdpsi1+dt1)   \n",
    "    dm2 = dq2*spsi+q*(sdpsi2+dt2)   \n",
    "\n",
    "    # top and bottom parts\n",
    "    Ldm1 = Lop(dm1)\n",
    "    Ldm2 = Lop(dm2) \n",
    "    top = redot(gradF,d2m1)+hessianF(Lpsi, Ldm1, Ldm2, d, pars)            \n",
    "    bottom = redot(gradF,d2m2)+hessianF(Lpsi, Ldm2, Ldm2,d, pars)\n",
    "    \n",
    "    return top, bottom\n",
    "\n",
    "def calc_beta(vars,grads,etas,pars,reused,d):\n",
    "    top = bottom = 0\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        top0,bottom0 = calc_beta0(vars,grads,etas,pars,reused,d,st,end)\n",
    "        top+=top0\n",
    "        bottom+=bottom0    \n",
    "    return float(top/bottom)\n",
    "\n",
    "def calc_alpha0(vars,grads,etas,pars,reused,d,st,end):    \n",
    "    (q,psi,x) = (vars['prb'], vars['psi'], vars['fshift'][st:end])    \n",
    "    (ix,ex,rho) = (pars['ishift'][st:end],pars['extra'],pars['rho'])\n",
    "    (dpsi1,dq1,dx1) = (grads['psi'], grads['prb'], grads['fshift'][st:end])\n",
    "    (dpsi2,dq2,dx2) = (etas['psi'], etas['prb'], etas['fshift'][st:end])    \n",
    "    (spsi,Lpsi,gradF) = (reused['spsi'][st:end],reused['Lpsi'][st:end], reused['gradF'][st:end])\n",
    "    x = cp.array(x)\n",
    "    ix = cp.array(ix)\n",
    "    spsi = cp.array(spsi)\n",
    "    Lpsi = cp.array(Lpsi)\n",
    "    gradF = cp.array(gradF)\n",
    "    dx1 = cp.array(dx1)\n",
    "    dx2 = cp.array(dx2)\n",
    "    d = cp.array(d[st:end])\n",
    "\n",
    "    top=-redot(dx1,dx2)\n",
    "    # top part\n",
    "    if st==0:\n",
    "        top += -redot(dpsi1,dpsi2)-redot(dq1,dq2)\n",
    "        \n",
    "    # scale variable for the hessian\n",
    "    (dpsi,dq,dx) = (etas['psi']*rho[0], etas['prb']*rho[1], etas['fshift'][st:end]*rho[2])\n",
    "    dx = cp.array(dx)\n",
    "\n",
    "    # frequencies        \n",
    "    xi1 = cp.fft.fftfreq(npatch).astype('float32')    \n",
    "    [xi2, xi1] = cp.meshgrid(xi1, xi1)\n",
    "\n",
    "    # multipliers in frequencies\n",
    "    dx = dx[:,:,cp.newaxis,cp.newaxis]\n",
    "    w = cp.exp(-2*cp.pi*1j * (xi2*x[:, 1, None, None]+xi1*x[:, 0, None, None]))\n",
    "    w1 = xi1*dx[:,0]+xi2*dx[:,1]\n",
    "    w2 = xi1**2*dx[:,0]**2+ 2*xi1*xi2*(dx[:,0]*dx[:,1]) + xi2**2*dx[:,1]**2\n",
    "    \n",
    "    # DT,D2T terms, and Spsi\n",
    "    tmp = Ex(dpsi,ix)     \n",
    "    tmp = cp.fft.fft2(tmp)    \n",
    "    sdpsi = cp.fft.ifft2(w*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    dt2 = -2*cp.pi*1j*cp.fft.ifft2(w*w1*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    \n",
    "    tmp = Ex(psi,ix)     \n",
    "    tmp = cp.fft.fft2(tmp)\n",
    "    dt = -2*cp.pi*1j*cp.fft.ifft2(w*w1*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    d2t = -4*cp.pi**2*cp.fft.ifft2(w*w2*tmp)[:,ex:nprb+ex,ex:nprb+ex]\n",
    "    \n",
    "    # DM and D2M terms\n",
    "    d2m2 = q*(2*dt2 + d2t)+2*dq*sdpsi+2*dq*dt\n",
    "    dm = dq*spsi+q*(sdpsi+dt)   \n",
    "            \n",
    "    # bottom part\n",
    "    Ldm = Lop(dm)\n",
    "    bottom = redot(gradF,d2m2)+hessianF(Lpsi, Ldm, Ldm,d,pars)\n",
    "    \n",
    "    return top/bottom, top, bottom\n",
    "\n",
    "\n",
    "def calc_alpha(vars,grads,etas,pars,reused,d):    \n",
    "    top = bottom = 0\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        alpha0,top0,bottom0 = calc_alpha0(vars,grads,etas,pars,reused,d,st,end)    \n",
    "        top+=top0\n",
    "        bottom+=bottom0\n",
    "    \n",
    "    return float(top/bottom), float(top), float(bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minimization functional and calculation of reused arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minf0(Lpsi,d,pars,st,end):\n",
    "    Lpsi = cp.array(Lpsi[st:end])\n",
    "    d = cp.array(d[st:end])\n",
    "    if pars['model']=='Gaussian':\n",
    "        f = cp.linalg.norm(cp.abs(Lpsi)-d)**2/(n*n*npos)    \n",
    "    else:        \n",
    "        f = cp.sum(cp.abs(Lpsi)**2-2*d*cp.log(cp.abs(Lpsi)+pars['eps']))/(n*n*npos)          \n",
    "        # loss = torch.nn.PoissonNLLLoss(log_input=False, full=True, size_average=None, eps=pars['eps'], reduce=None, reduction='sum')\n",
    "        # f = loss(torch.as_tensor(cp.abs(Lpsi)**2,device='cuda'),torch.as_tensor(d,device='cuda'))    \n",
    "    return f\n",
    "\n",
    "def minf(Lpsi,d,pars):\n",
    "    f = 0\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        f += minf0(Lpsi,d,pars,st,end)\n",
    "    return float(f)\n",
    "\n",
    "def calc_reused0(reused, vars, pars, st, end):\n",
    "    \n",
    "    psi = vars['psi']\n",
    "    q = vars['prb']\n",
    "    x = vars['fshift'][st:end]\n",
    "    ix = pars['ishift'][st:end]\n",
    "    ex = pars['extra']\n",
    "\n",
    "    x = cp.array(x)\n",
    "    ix = cp.array(ix)\n",
    "    spsi = Sop(psi,ix,x,ex)\n",
    "    reused['Lpsi'][st:end] = Lop(spsi*q).get()     \n",
    "    reused['spsi'][st:end] = spsi.get()\n",
    "    return reused\n",
    "\n",
    "def calc_reused(vars, pars):\n",
    "    reused = {}\n",
    "    reused['spsi'] = np.zeros([npos,nprb,nprb],dtype='complex64')\n",
    "    reused['Lpsi'] = np.zeros([npos,n,n],dtype='complex64')\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        calc_reused0(reused, vars, pars, st,end)\n",
    "    return reused\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Lpsi0(Lpsi,q,psi,ix,x,ex,st,end):\n",
    "    x = cp.array(x[st:end])\n",
    "    ix = cp.array(ix[st:end])\n",
    "    spsi = Sop(psi,ix,x,ex)\n",
    "    Lpsi[st:end] = Lop(spsi*q).get()     \n",
    "\n",
    "def calc_Lpsi(q,psi,ix,x,ex):\n",
    "    Lpsi = np.zeros([npos,n,n],dtype='complex64')\n",
    "    for k in range(nchunk):         \n",
    "        st = k*chunk         \n",
    "        end = min((k+1)*chunk,npos)\n",
    "        calc_Lpsi0(Lpsi,q,psi,ix,x,ex,st,end)\n",
    "    return Lpsi\n",
    "    \n",
    "\n",
    "def plot_debug(vars,etas,pars,top,bottom,alpha,data,i):\n",
    "    '''Check the minimization functional behaviour'''\n",
    "    if i % pars['vis_step'] == 0 and pars['vis_step'] != -1 and show:\n",
    "        (q,psi,x) = (vars['prb'], vars['psi'], vars['fshift'])    \n",
    "        (ix,ex,rho) = (pars['ishift'],pars['extra'],pars['rho'])\n",
    "        (dpsi2,dq2,dx2) = (etas['psi'], etas['prb'], etas['fshift'])    \n",
    "\n",
    "        npp = 3\n",
    "        errt = np.zeros(npp*2)\n",
    "        errt2 = np.zeros(npp*2)\n",
    "        for k in range(0,npp*2):\n",
    "            psit = psi+(alpha*k/(npp-1))*rho[0]*dpsi2\n",
    "            qt = q+(alpha*k/(npp-1))*rho[1]*dq2\n",
    "            xt = x+(alpha*k/(npp-1))*rho[2]*dx2\n",
    "\n",
    "            errt[k] = minf(calc_Lpsi(qt,psit,ix,xt,ex),data,pars)\n",
    "                    \n",
    "        t = alpha*(np.arange(2*npp))/(npp-1)    \n",
    "        errt2 = minf(calc_Lpsi(q,psi,ix,x,ex),data,pars)\n",
    "        errt2 = errt2 -top*t/(n*n*npos)+0.5*bottom*t**2/(n*n*npos)    \n",
    "        \n",
    "        plt.plot(alpha*np.arange(2*npp)/(npp-1),errt,'.')\n",
    "        plt.plot(alpha*np.arange(2*npp)/(npp-1),errt2,'.')\n",
    "        plt.show()\n",
    "\n",
    "def vis_debug(vars,pars,i):\n",
    "    '''Visualization and data saving'''\n",
    "    if i % pars['vis_step'] == 0 and pars['vis_step'] != -1:\n",
    "        (q,psi,x) = (vars['prb'], vars['psi'], vars['fshift'])        \n",
    "        mshow_polar(psi,show)\n",
    "        \n",
    "        mshow_polar(q,show)\n",
    "        mshow_polar(q[nprb//2-nprb//8:nprb//2+nprb//8,nprb//2+nprb//4:nprb//2+nprb//2],show)\n",
    "        write_tiff(cp.angle(psi),f'{path_out}_{pars['flg']}/crec_psi_angle/{i:03}')\n",
    "        write_tiff(cp.abs(psi),f'{path_out}_{pars['flg']}/crec_psi_abs/{i:03}')\n",
    "        write_tiff(cp.angle(q),f'{path_out}_{pars['flg']}/crec_prb_angle/{i:03}')\n",
    "        write_tiff(cp.abs(q),f'{path_out}_{pars['flg']}/crec_prb_abs/{i:03}')\n",
    "        cp.save(f'{path_out}_{pars['flg']}/crec_shift_{i:03}',x)\n",
    "        plt.plot(x[:,0]-fshifts_init[:,0],'.',label='y')\n",
    "        plt.plot(x[:,1]-fshifts_init[:,1],'.',label='x')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def error_debug(vars, pars, reused, data, i):\n",
    "    '''Visualization and data saving'''\n",
    "    if i % pars['err_step'] == 0 and pars['err_step'] != -1:\n",
    "        err = minf(reused['Lpsi'],data,pars)\n",
    "        print(f'{i}) {err=:1.5e}',flush=True)                        \n",
    "        vars['table'].loc[len(vars['table'])] = [i, err, time.time()]\n",
    "        vars['table'].to_csv(f'{pars['flg']}', index=False)            \n",
    "\n",
    "def grad_debug(alpha, grads, pars, i):\n",
    "    if i % pars['grad_step'] == 0 and pars['grad_step'] != -1:\n",
    "        print(f'(alpha,psi,prb,shift): {alpha:.1e} {cp.linalg.norm(grads['psi']):.1e},{cp.linalg.norm(grads['prb']):.1e},{cp.linalg.norm(grads['fshift']):.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prb_init = cp.ones([nprb,nprb],dtype='complex64')\n",
    "v = cp.ones(nprb)\n",
    "ppad = n//16\n",
    "vv = cp.sin(cp.linspace(0.0,cp.pi/2,ppad))\n",
    "v[:ppad] = vv\n",
    "v[nprb-ppad:] = vv[::-1]\n",
    "v = cp.outer(v,v)\n",
    "prb_init*=v\n",
    "mshow_polar(prb_init,mshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilinear Hessian method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BH(data, vars, pars):\n",
    "   \n",
    "    if pars['model']=='Gaussian':\n",
    "        # work with sqrt\n",
    "        data = np.sqrt(data)\n",
    "        \n",
    "    alpha = 1\n",
    "    for i in range(pars['niter']):                             \n",
    "        reused = calc_reused(vars, pars)\n",
    "        error_debug(vars, pars, reused, data, i)\n",
    "        vis_debug(vars, pars, i)            \n",
    "      \n",
    "        gradientF(pars,reused,data) \n",
    "        grads = gradients(vars,pars,reused)\n",
    "        if i==0 or pars['method']=='BH-GD':\n",
    "            etas = {}\n",
    "            etas['psi'] = -grads['psi']\n",
    "            etas['prb'] = -grads['prb']\n",
    "            etas['fshift'] = -grads['fshift']\n",
    "        else:      \n",
    "            beta = calc_beta(vars, grads, etas, pars, reused, data)\n",
    "            etas['psi'] = -grads['psi'] + beta*etas['psi']\n",
    "            etas['prb'] = -grads['prb'] + beta*etas['prb']\n",
    "            etas['fshift'] = -grads['fshift'] + beta*etas['fshift']\n",
    "\n",
    "        \n",
    "        alpha,top,bottom = calc_alpha(vars, grads, etas, pars, reused, data)         \n",
    "\n",
    "        plot_debug(vars,etas,pars,top,bottom,alpha,data,i)\n",
    "        grad_debug(alpha,grads,pars,i)\n",
    "        \n",
    "        vars['psi'] += pars['rho'][0]*alpha*etas['psi']\n",
    "        vars['prb'] += pars['rho'][1]*alpha*etas['prb']        \n",
    "        vars['fshift'] += pars['rho'][2]*alpha*etas['fshift']\n",
    "        \n",
    "    return vars\n",
    "\n",
    "# fixed variables\n",
    "pars = {'niter':2049, 'err_step': 1, 'vis_step': 32, 'grad_step': -1}\n",
    "pars['rho'] = [1,1.5,0.1]\n",
    "pars['ishift'] = np.floor(shifts).astype('int32')\n",
    "pars['extra'] = extra\n",
    "pars['eps'] = 1e-9\n",
    "pars['model'] = 'Gaussian'\n",
    "pars['method'] = 'BH-CG'\n",
    "pars['flg'] = f'{pars['method']}_{pars['rho'][0]}_{pars['rho'][1]}_{pars['rho'][2]}'\n",
    "\n",
    "vars = {}\n",
    "vars['psi'] = rec_paganin.copy()\n",
    "vars['prb'] = prb_init.copy()#cp.ones([nprb,nprb],dtype='complex64')\n",
    "vars['fshift'] = np.array(shifts-np.floor(shifts).astype('int32')).astype('float32')\n",
    "vars['table'] = pd.DataFrame(columns=[\"iter\", \"err\", \"time\"])\n",
    "\n",
    "fshifts_init = vars['fshift'].copy()\n",
    "vars = BH(data, vars, pars)      \n",
    "\n",
    "mshow_polar(vars['psi'],mshow)\n",
    "mshow_polar(vars['prb'],mshow)\n",
    "erra = vars['table']['err'].values\n",
    "# times=vars['table']['time'].values\n",
    "# times-=times[0]\n",
    "# print(times)\n",
    "rec_pos = (vars['fshift']+pars['ishift'])\n",
    "plt.plot(erra,label=pars['method'])\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(shifts[:,1],shifts[:,0],'r.')\n",
    "plt.plot(rec_pos[:,1],rec_pos[:,0],'g.')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holotomocupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
