{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad77fab-e206-47c1-9655-088d14fe30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import h5py\n",
    "from holotomocupy.holo import G, GT\n",
    "from holotomocupy.shift import S, ST\n",
    "from holotomocupy.recon_methods import multiPaganin\n",
    "from holotomocupy.utils import *\n",
    "from holotomocupy.proc import remove_outliers\n",
    "# Use managed memory\n",
    "# cp.cuda.set_allocator(cp.cuda.MemoryPool(cp.cuda.malloc_managed).malloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fdd65-1cff-451e-865e-56cd8b7882a6",
   "metadata": {},
   "source": [
    "# Init data sizes and parametes of the PXM of ID16A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa16f2-1f9c-4b3a-a330-e10942f12234",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2048  # object size in each dimension\n",
    "detector_pixelsize = 3.03751e-6\n",
    "energy = 33.35  # [keV] xray energy\n",
    "wavelength = 1.2398419840550367e-09/energy  # [m] wave length\n",
    "focusToDetectorDistance = 1.28  # [m]\n",
    "sx0 = 1.286e-3\n",
    "z1 = np.array([4.236e-3,4.3625e-3,4.86850e-3,5.91950e-3])-sx0\n",
    "z2 = focusToDetectorDistance-z1\n",
    "distances = (z1*z2)/focusToDetectorDistance\n",
    "magnifications = focusToDetectorDistance/z1\n",
    "norm_magnifications = magnifications/magnifications[0]\n",
    "voxelsize = np.abs(detector_pixelsize/magnifications[0]*2048/n)  # object voxel size\n",
    "\n",
    "show = True\n",
    "path = f'/data/vnikitin/ESRF/ID16A/20240924/AtomiumS2/'\n",
    "pfile = f'AtomiumS2_HT_007nm'\n",
    "path_out = f'/data/vnikitin/ESRF/ID16A/20240924_rec/AtomiumS2/'\n",
    "print(f'{voxelsize=}')\n",
    "ntheta=1800\n",
    "ndist=4\n",
    "st=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb1696-bb30-496e-8c3d-565f2791112c",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03cfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndimage\n",
    "def remove_outliers(data, dezinger, dezinger_threshold):    \n",
    "    res = data.copy()\n",
    "    if (int(dezinger) > 0):\n",
    "        w = int(dezinger)\n",
    "        # print(data.shape)\n",
    "        fdata = ndimage.median_filter(data, [1,w, w])\n",
    "        print(np.sum(np.abs(data-fdata)>fdata*dezinger_threshold))\n",
    "        res[:] = np.where(np.abs(data-fdata)>fdata*dezinger_threshold, fdata, data)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref00 = np.zeros([ndist,2048,2048],dtype='float32')\n",
    "ref01 = np.zeros([ndist,2048,2048],dtype='float32')\n",
    "dark00 = np.zeros([ndist,2048,2048],dtype='float32')\n",
    "    \n",
    "mmeans = np.zeros(8)\n",
    "\n",
    "for k in range(ndist):\n",
    "    \n",
    "    tmp = np.zeros([n,n],dtype='float32')\n",
    "    for l in range(20):\n",
    "        fname=f'{path}{pfile}_{k+1}_/ref{l:04}_0000.edf'\n",
    "        #print(fname)\n",
    "        tmp += dxchange.read_edf(fname)[0]\n",
    "    tmp/=20\n",
    "    ref00[k] = tmp\n",
    "\n",
    "    tmp = np.zeros([n,n],dtype='float32')\n",
    "    for l in range(20):\n",
    "        fname = f'{path}{pfile}_{k+1}_/ref{l:04}_1800.edf'\n",
    "        #print(fname)\n",
    "        tmp += dxchange.read_edf(fname)[0]\n",
    "    tmp/=20\n",
    "    ref01[k] = tmp\n",
    "\n",
    "    tmp = np.zeros([n,n],dtype='float32')\n",
    "    for l in range(20):\n",
    "        fname = f'{path}{pfile}_{k+1}_/darkend{l:04}.edf'\n",
    "        #print(fname)\n",
    "        tmp += dxchange.read_edf(fname)[0]\n",
    "    tmp/=20\n",
    "\n",
    "    dark00[k] = tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = ref00.copy()\n",
    "dark = dark00.copy()\n",
    "ref-=dark\n",
    "\n",
    "ref[ref<0]=0\n",
    "\n",
    "ref[:,1320//3:1320//3+25//3,890//3:890//3+25//3] = ref[:,1280//3:1280//3+25//3,890//3:890//3+25//3]\n",
    "    \n",
    "ref[:] = remove_outliers(ref[:], 3, 0.9)     \n",
    "\n",
    "dark/=np.mean(ref)\n",
    "ref/=np.mean(ref)\n",
    "\n",
    "for k in range(int(np.log2(2048//n))):\n",
    "    ref = (ref[:,::2]+ref[:,1::2])*0.5\n",
    "    ref = (ref[:,:,::2]+ref[:,:,1::2])*0.5    \n",
    "    dark = (dark[:,::2]+dark[:,1::2])*0.5\n",
    "    dark = (dark[:,:,::2]+dark[:,:,1::2])*0.5    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_shift(psi, p):\n",
    "    \"\"\"Apply shift for all projections.\"\"\"\n",
    "    psi = cp.array(psi)\n",
    "    p = cp.array(p)\n",
    "    tmp = cp.pad(psi,((0,0),(n//2,n//2),(n//2,n//2)), 'symmetric')\n",
    "    [x, y] = cp.meshgrid(cp.fft.rfftfreq(2*n),\n",
    "                         cp.fft.fftfreq(2*n))\n",
    "    shift = cp.exp(-2*cp.pi*1j *\n",
    "                   (x*p[:, 1, None, None]+y*p[:, 0, None, None]))\n",
    "    res0 = cp.fft.irfft2(shift*cp.fft.rfft2(tmp))\n",
    "    res = res0[:, n//2:3*n//2, n//2:3*n//2].get()\n",
    "    return res\n",
    "\n",
    "def _upsampled_dft(data, ups,\n",
    "                   upsample_factor=1, axis_offsets=None):\n",
    "\n",
    "    im2pi = 1j * 2 * cp.pi\n",
    "    tdata = data.copy()\n",
    "    kernel = (cp.tile(cp.arange(ups), (data.shape[0], 1))-axis_offsets[:, 1:2])[\n",
    "        :, :, None]*cp.fft.fftfreq(data.shape[2], upsample_factor)\n",
    "    kernel = cp.exp(-im2pi * kernel)\n",
    "    tdata = cp.einsum('ijk,ipk->ijp', kernel, tdata)\n",
    "    kernel = (cp.tile(cp.arange(ups), (data.shape[0], 1))-axis_offsets[:, 0:1])[\n",
    "        :, :, None]*cp.fft.fftfreq(data.shape[1], upsample_factor)\n",
    "    kernel = cp.exp(-im2pi * kernel)\n",
    "    rec = cp.einsum('ijk,ipk->ijp', kernel, tdata)\n",
    "\n",
    "    return rec\n",
    "\n",
    "def registration_shift(src_image, target_image, upsample_factor=1, space=\"real\"):\n",
    "\n",
    "    src_image=cp.array(src_image)\n",
    "    target_image=cp.array(target_image)\n",
    "    # assume complex data is already in Fourier space\n",
    "    if space.lower() == 'fourier':\n",
    "        src_freq = src_image\n",
    "        target_freq = target_image\n",
    "    # real data needs to be fft'd.\n",
    "    elif space.lower() == 'real':\n",
    "        src_freq = cp.fft.fft2(src_image)\n",
    "        target_freq = cp.fft.fft2(target_image)\n",
    "\n",
    "    # Whole-pixel shift - Compute cross-correlation by an IFFT\n",
    "    shape = src_freq.shape\n",
    "    image_product = src_freq * target_freq.conj()\n",
    "    cross_correlation = cp.fft.ifft2(image_product)\n",
    "    A = cp.abs(cross_correlation)\n",
    "    maxima = A.reshape(A.shape[0], -1).argmax(1)\n",
    "    maxima = cp.column_stack(cp.unravel_index(maxima, A[0, :, :].shape))\n",
    "\n",
    "    midpoints = cp.array([cp.fix(axis_size / 2)\n",
    "                          for axis_size in shape[1:]])\n",
    "\n",
    "    shifts = cp.array(maxima, dtype=cp.float64)\n",
    "    ids = cp.where(shifts[:, 0] > midpoints[0])\n",
    "    shifts[ids[0], 0] -= shape[1]\n",
    "    ids = cp.where(shifts[:, 1] > midpoints[1])\n",
    "    shifts[ids[0], 1] -= shape[2]\n",
    "    \n",
    "    if upsample_factor > 1:\n",
    "        # Initial shift estimate in upsampled grid\n",
    "        shifts = cp.round(shifts * upsample_factor) / upsample_factor\n",
    "        upsampled_region_size = cp.ceil(upsample_factor * 1.5)\n",
    "        # Center of output array at dftshift + 1\n",
    "        dftshift = cp.fix(upsampled_region_size / 2.0)\n",
    "\n",
    "        normalization = (src_freq[0].size * upsample_factor ** 2)\n",
    "        # Matrix multiply DFT around the current shift estimate\n",
    "\n",
    "        sample_region_offset = dftshift - shifts*upsample_factor\n",
    "        cross_correlation = _upsampled_dft(image_product.conj(),\n",
    "                                                upsampled_region_size,\n",
    "                                                upsample_factor,\n",
    "                                                sample_region_offset).conj()\n",
    "        cross_correlation /= normalization\n",
    "        # Locate maximum and map back to original pixel grid\n",
    "        A = cp.abs(cross_correlation)\n",
    "        maxima = A.reshape(A.shape[0], -1).argmax(1)\n",
    "        maxima = cp.column_stack(\n",
    "            cp.unravel_index(maxima, A[0, :, :].shape))\n",
    "\n",
    "        maxima = cp.array(maxima, dtype=cp.float64) - dftshift\n",
    "\n",
    "        shifts = shifts + maxima / upsample_factor\n",
    "           \n",
    "    return shifts\n",
    "\n",
    "shifts = cp.zeros([ndist,2],dtype='float32')\n",
    "ref_shifted=ref.copy()\n",
    "print(ref.shape)\n",
    "for k in range(ndist):\n",
    "    a=cp.fft.fft2(cp.array(ref_shifted[k:k+1]))\n",
    "    shifts[k] = registration_shift(ref_shifted[k:k+1],ref[0:1],upsample_factor=1000)\n",
    "print(shifts)    \n",
    "# shifts = cp.median(shifts,axis=0)+cp.array(shifts_random)\n",
    "\n",
    "ref_shifted_check = ref_shifted.copy()\n",
    "for k in range(ndist):\n",
    "    ref_shifted_check[k:k+1] = apply_shift(ref_shifted_check[k:k+1],-shifts[k:k+1])\n",
    "    mshow_complex(ref_shifted[k]-ref_shifted[0]+1j*(ref_shifted_check[k]-ref_shifted_check[0]),show,vmax=0.05,vmin=-0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9933cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde55de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holotomocupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
