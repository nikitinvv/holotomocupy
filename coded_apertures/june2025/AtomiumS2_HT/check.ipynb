{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad77fab-e206-47c1-9655-088d14fe30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import cupyx.scipy.ndimage as ndimage\n",
    "# Use managed memory\n",
    "import h5py\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=f\".*peer.*\")\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fdd65-1cff-451e-865e-56cd8b7882a6",
   "metadata": {},
   "source": [
    "# Init data sizes and parametes of the PXM of ID16A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfile = f'Y350c_HT_015nm'\n",
    "path = f'/data/vnikitin/ESRF/ID16A/brain/20240515/Y350c'\n",
    "path_out = f'/data/vnikitin/ESRF/ID16A/brain_rec/20240515/Y350c'\n",
    "with h5py.File(f'{path_out}/{pfile}.h5') as fid:\n",
    "    detector_pixelsize = fid['/exchange/detector_pixelsize'][0]    \n",
    "    focusToDetectorDistance = fid['/exchange/focusdetectordistance'][0]    \n",
    "    z1 = fid['/exchange/z1'][:]        \n",
    "    theta = fid['/exchange/theta'][::step]\n",
    "    shifts = fid['/exchange/shifts'][::step]\n",
    "    attrs = fid['/exchange/attrs'][::step]\n",
    "    pos_shifts = fid['/exchange/pos_shifts'][::step]*1e-6\n",
    "    shape = fid['/exchange/data0'][::step].shape\n",
    "    shape_ref = fid['/exchange/data_white_start0'].shape\n",
    "    shape_dark = fid['/exchange/data_dark0'].shape\n",
    "    #pos_shifts-=pos_shifts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da169abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndist=4\n",
    "ntheta,n = shape[:2]\n",
    "ndark = shape_dark[0]\n",
    "nref = shape_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185647a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndist,ntheta,n)\n",
    "print(nref,ndark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa16f2-1f9c-4b3a-a330-e10942f12234",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = 33.35  # [keV] xray energy\n",
    "wavelength = 1.2398419840550367e-09/energy  # [m] wave length\n",
    "z2 = focusToDetectorDistance-z1\n",
    "distances = (z1*z2)/focusToDetectorDistance\n",
    "magnifications = focusToDetectorDistance/z1\n",
    "norm_magnifications = magnifications/magnifications[0]\n",
    "show = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfa262",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_random = np.zeros([ntheta,ndist,2],dtype='float32')\n",
    "# shifts_random_test = np.zeros([ntheta,ndist,2],dtype='float32')\n",
    "for k in range(ndist):\n",
    "    # shifts_random_test[:,k] = np.loadtxt(f'{path}/{pfile}_{k+1}_/correct.txt')[:ntheta].astype('float32')/norm_magnifications[k]    \n",
    "    #s = np.loadtxt(f'{path}{pfile}_{k+1}_/correct.txt').astype('float32')[st:st+ntheta]/norm_magnifications[k]        \n",
    "    shifts_random[:,k,0] = shifts[:,k,1]/norm_magnifications[k]    #+(1024-(2048+0-0)/2)*(1/norm_magnifications[k]-1)#/norm_magnifications[k]\n",
    "    shifts_random[:,k,1] = shifts[:,k,0]/norm_magnifications[k]    #+(1024-(2048+0-0)/2)*(1/norm_magnifications[k]-1)#/norm_magnifications[k]\n",
    "# plt.plot(shifts_random[:,0,1])\n",
    "print(shifts_random[:,0])\n",
    "# print(shifts_random_test[:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98629421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_shift(psi, p):\n",
    "    \"\"\"Apply shift for all projections.\"\"\"\n",
    "    psi = cp.array(psi)\n",
    "    p = cp.array(p)\n",
    "    tmp = cp.pad(psi,((0,0),(n//2,n//2),(n//2,n//2)), 'symmetric')\n",
    "    [x, y] = cp.meshgrid(cp.fft.rfftfreq(2*n),\n",
    "                         cp.fft.fftfreq(2*n))\n",
    "    shift = cp.exp(-2*cp.pi*1j *\n",
    "                   (x*p[:, 1, None, None]+y*p[:, 0, None, None]))\n",
    "    res0 = cp.fft.irfft2(shift*cp.fft.rfft2(tmp))\n",
    "    res = res0[:, n//2:3*n//2, n//2:3*n//2].get()\n",
    "    return res\n",
    "\n",
    "def _upsampled_dft(data, ups,\n",
    "                   upsample_factor=1, axis_offsets=None):\n",
    "\n",
    "    im2pi = 1j * 2 * cp.pi\n",
    "    tdata = data.copy()\n",
    "    kernel = (cp.tile(cp.arange(ups), (data.shape[0], 1))-axis_offsets[:, 1:2])[\n",
    "        :, :, None]*cp.fft.fftfreq(data.shape[2], upsample_factor)\n",
    "    kernel = cp.exp(-im2pi * kernel)\n",
    "    tdata = cp.einsum('ijk,ipk->ijp', kernel, tdata)\n",
    "    kernel = (cp.tile(cp.arange(ups), (data.shape[0], 1))-axis_offsets[:, 0:1])[\n",
    "        :, :, None]*cp.fft.fftfreq(data.shape[1], upsample_factor)\n",
    "    kernel = cp.exp(-im2pi * kernel)\n",
    "    rec = cp.einsum('ijk,ipk->ijp', kernel, tdata)\n",
    "\n",
    "    return rec\n",
    "\n",
    "def registration_shift(src_image, target_image, upsample_factor=1, space=\"real\"):\n",
    "    # print(src_image.shape)\n",
    "    src_image=cp.array(src_image)\n",
    "    target_image=cp.array(target_image)\n",
    "    # assume complex data is already in Fourier space\n",
    "    if space.lower() == 'fourier':\n",
    "        src_freq = src_image\n",
    "        target_freq = target_image\n",
    "    # real data needs to be fft'd.\n",
    "    elif space.lower() == 'real':\n",
    "        src_freq = cp.fft.fft2(src_image)\n",
    "        target_freq = cp.fft.fft2(target_image)\n",
    "\n",
    "    # Whole-pixel shift - Compute cross-correlation by an IFFT\n",
    "    shape = src_freq.shape\n",
    "    image_product = src_freq * target_freq.conj()\n",
    "    cross_correlation = cp.fft.ifft2(image_product)\n",
    "    A = cp.abs(cross_correlation)\n",
    "    maxima = A.reshape(A.shape[0], -1).argmax(1)\n",
    "    maxima = cp.column_stack(cp.unravel_index(maxima, A[0, :, :].shape))\n",
    "\n",
    "    midpoints = cp.array([cp.fix(axis_size / 2)\n",
    "                          for axis_size in shape[1:]])\n",
    "\n",
    "    shifts = cp.array(maxima, dtype=cp.float64)\n",
    "    ids = cp.where(shifts[:, 0] > midpoints[0])\n",
    "    shifts[ids[0], 0] -= shape[1]\n",
    "    ids = cp.where(shifts[:, 1] > midpoints[1])\n",
    "    shifts[ids[0], 1] -= shape[2]\n",
    "    \n",
    "    if upsample_factor > 1:\n",
    "        # Initial shift estimate in upsampled grid\n",
    "        shifts = cp.round(shifts * upsample_factor) / upsample_factor\n",
    "        upsampled_region_size = cp.ceil(upsample_factor * 1.5)\n",
    "        # Center of output array at dftshift + 1\n",
    "        dftshift = cp.fix(upsampled_region_size / 2.0)\n",
    "\n",
    "        normalization = (src_freq[0].size * upsample_factor ** 2)\n",
    "        # Matrix multiply DFT around the current shift estimate\n",
    "\n",
    "        sample_region_offset = dftshift - shifts*upsample_factor\n",
    "        cross_correlation = _upsampled_dft(image_product.conj(),\n",
    "                                                upsampled_region_size,\n",
    "                                                upsample_factor,\n",
    "                                                sample_region_offset).conj()\n",
    "        cross_correlation /= normalization\n",
    "        # Locate maximum and map back to original pixel grid\n",
    "        A = cp.abs(cross_correlation)\n",
    "        maxima = A.reshape(A.shape[0], -1).argmax(1)\n",
    "        maxima = cp.column_stack(\n",
    "            cp.unravel_index(maxima, A[0, :, :].shape))\n",
    "\n",
    "        maxima = cp.array(maxima, dtype=cp.float64) - dftshift\n",
    "\n",
    "        shifts = shifts + maxima / upsample_factor\n",
    "           \n",
    "    return shifts\n",
    "\n",
    "\n",
    "rdata_scaled_shifted = rdata_scaled.copy()\n",
    "for j in range(100):\n",
    "    for k in range(ndist):\n",
    "        mstep = 3000//100//step\n",
    "        rdata_scaled_shifted[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled_shifted[j*mstep:j*mstep+mstep,k],-shifts_random[j*mstep:j*mstep+mstep,k])\n",
    "        # mshow_complex(rdata_scaled[0,k]-rdata_scaled[1,k]+1j*(rdata_scaled_shifted[0,k]-rdata_scaled_shifted[1,k]),show)\n",
    "\n",
    "write_tiff(rdata_scaled[:,0],'/data/tmp/rdata_scaled',overwrite=True)\n",
    "write_tiff(rdata_scaled_shifted[:,0],'/data/tmp/rdata_scaled_shifted0',overwrite=True)\n",
    "write_tiff(rdata_scaled[:,2],'/data/tmp/rdata_scaled2',overwrite=True)\n",
    "write_tiff(rdata_scaled_shifted[:,2],'/data/tmp/rdata_scaled_shifted2',overwrite=True)\n",
    "shifts = cp.zeros([ntheta,ndist,2],dtype='float32')\n",
    "rdata_scaled_shifted_check = rdata_scaled.copy()\n",
    "for j in range(100):\n",
    "    for k in range(ndist):\n",
    "        mstep = 3000//100//step\n",
    "        shifts[j*mstep:j*mstep+mstep,k] = registration_shift(rdata_scaled_shifted[j*mstep:j*mstep+mstep,k],rdata_scaled_shifted[j*mstep:j*mstep+mstep,0],upsample_factor=1000)\n",
    "        # rdata_scaled_shifted_check[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],-shifts[j*mstep:j*mstep+mstep,k]-shifts_random[j*mstep:j*mstep+mstep,k])\n",
    "# write_tiff(rdata_scaled_shifted_check[:,0],'/data/tmp/rdata_scaled_shifted_check0',overwrite=True)\n",
    "# write_tiff(rdata_scaled_shifted_check[:,2],'/data/tmp/rdata_scaled_shifted_check2',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shifts[:,:,0].get())\n",
    "plt.show()\n",
    "plt.plot(shifts[:,:,1].get())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "pshifts = scipy.io.loadmat('/data/vnikitin/ESRF/ID16A/brain/20240515/Y350c/Y350c_HT_015nm_/rhapp_fixed.mat')['pshifts'][0,0][0]\n",
    "pshifts=-pshifts.swapaxes(0,2)[:3000:step]\n",
    "\n",
    "for k in range(1,4):\n",
    "    plt.plot(pshifts[:,k,1])\n",
    "    plt.plot(shifts[:,k,1].get())\n",
    "    plt.plot(pshifts[:,k,0])\n",
    "    plt.plot(shifts[:,k,0].get())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6c044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifts = cp.median(shifts,axis=0)+cp.array(shifts_random)\n",
    "shifts = cp.array(pshifts)+cp.array(shifts_random)\n",
    "rdata_scaled_shifted_check=rdata_scaled.copy()\n",
    "for j in range(100):\n",
    "    for k in range(ndist):\n",
    "        mstep = 3000//100//step\n",
    "        # shifts[j*mstep:j*mstep+mstep,k] = registration_shift(rdata_scaled_shifted[j*mstep:j*mstep+mstep,k],rdata_scaled_shifted[j*mstep:j*mstep+mstep,0],upsample_factor=1000)\n",
    "        rdata_scaled_shifted_check[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],-shifts[j*mstep:j*mstep+mstep,k])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(ndist):\n",
    "    mshow_complex(rdata_scaled_shifted[0,k]+1j*rdata_scaled_shifted[0,0],show)\n",
    "    mshow_complex(rdata_scaled_shifted_check[0,k]+1j*rdata_scaled_shifted_check[0,0],show)\n",
    "    mshow_complex(rdata_scaled_shifted[0,k]-rdata_scaled_shifted[0,0]+1j*(rdata_scaled_shifted_check[0,k]-rdata_scaled_shifted_check[0,0]),show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.loadtxt('/data/vnikitin/ESRF/ID16A/brain/20240515/Y350c/Y350c_HT_015nm_/correct_correct3D.txt')[:3000:step][:,::-1]\n",
    "\n",
    "plt.plot(s[:,1])\n",
    "plt.plot(s[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rdata_scaled_shifted_check3d = rdata_scaled_shifted_check[:,0].copy()\n",
    "for j in range(100):\n",
    "    mstep = 3000//100//step\n",
    "    rdata_scaled_shifted_check3d[j*mstep:j*mstep+mstep] = apply_shift(rdata_scaled_shifted_check3d[j*mstep:j*mstep+mstep],-s[j*mstep:j*mstep+mstep])\n",
    "    # mshow_complex(rdata_scaled[0,k]-rdata_scaled[1,k]+1j*(rdata_scaled_shifted[0,k]-rdata_scaled_shifted[1,k]),show)\n",
    "write_tiff(rdata_scaled_shifted_check3d[:],'/data/tmp/rdata_scaled_shifted_check3d',overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = cp.linspace(-1,1.25,len(shifts))\n",
    "# t = t**2*12*0\n",
    "# plt.plot(t.get())\n",
    "# plt.show()\n",
    "# shifts_final = shifts.copy()\n",
    "# for k in range(ndist):\n",
    "#     shifts_final[:,k,0]=shifts[:,k,0]+t#t*norm_magnifications[k])\n",
    "\n",
    "shifts_final = shifts.get()+s[:,np.newaxis]\n",
    "final = rdata_scaled.copy()\n",
    "for j in range(100):\n",
    "    for k in range(ndist):\n",
    "        mstep = 3000//100//step\n",
    "        final[j*mstep:j*mstep+mstep,k] = apply_shift(rdata_scaled[j*mstep:j*mstep+mstep,k],-shifts_final[j*mstep:j*mstep+mstep,k])\n",
    "\n",
    "write_tiff(final[:,0],'/data/tmp/ftmp0',overwrite=True)\n",
    "write_tiff(final[:,1],'/data/tmp/ftmp1',overwrite=True)\n",
    "write_tiff(final[:,2],'/data/tmp/ftmp2',overwrite=True)\n",
    "write_tiff(final[:,3],'/data/tmp/ftmp3',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ddb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e333a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(f'{path_out}/{pfile}_corr.h5','a') as fid:\n",
    "    try:\n",
    "        del fid[f'/exchange/cshifts_final']\n",
    "    except:\n",
    "        pass\n",
    "    fid.create_dataset(f'/exchange/cshifts_final',data = shifts_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holotomocupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
