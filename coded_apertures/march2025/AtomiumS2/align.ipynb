{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def phase_correlation_alignment(img1, img2):\n",
    "    \"\"\"Align img2 to img1 using Phase Correlation (Fourier shift).\"\"\"\n",
    "    # Convert images to float32 for FFT\n",
    "    img1_f = np.float32(img1)\n",
    "    img2_f = np.float32(img2)\n",
    "\n",
    "    # Compute phase correlation\n",
    "    shift = cv2.phaseCorrelate(img1_f, img2_f)\n",
    "    \n",
    "    # Extract translation components\n",
    "    tx, ty = shift[0]\n",
    "    return tx,ty\n",
    "\n",
    "def process_stack(imgs):\n",
    "    \"\"\"Align a stack of images assuming sequential order.\"\"\"\n",
    "    aligned_images = []\n",
    "    # base_img = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "    base_img = imgs[0]\n",
    "    aligned_images.append(base_img)\n",
    "\n",
    "    for i in range(1, len(imgs)):\n",
    "        img = imgs[i]\n",
    "        shiftx,shifty = phase_correlation_alignment(base_img, img)\n",
    "        print(f\"Image {i} aligned with translation: {shiftx,shifty}\")\n",
    "\n",
    "    return aligned_images\n",
    "\n",
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dxchange\n",
    "d = dxchange.read_tiff_stack('/data/tmp/psi_data/r_00000.tiff',ind=np.arange(1440))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /home/conda/feedstock_root/build_artifacts/libopencv_1734356343879/work/modules/features2d/src/sift.dispatch.cpp:512: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aligned \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m, in \u001b[0;36mprocess_stack\u001b[0;34m(imgs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(imgs)):\n\u001b[1;32m     41\u001b[0m     img \u001b[38;5;241m=\u001b[39m imgs[i]\n\u001b[0;32m---> 42\u001b[0m     aligned_img, shift \u001b[38;5;241m=\u001b[39m \u001b[43malign_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     aligned_images\u001b[38;5;241m.\u001b[39mappend(aligned_img)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m aligned with translation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshift\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36malign_images\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m      7\u001b[0m sift \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mSIFT_create()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Detect keypoints and descriptors\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m keypoints1, descriptors1 \u001b[38;5;241m=\u001b[39m \u001b[43msift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectAndCompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m keypoints2, descriptors2 \u001b[38;5;241m=\u001b[39m sift\u001b[38;5;241m.\u001b[39mdetectAndCompute(img2, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use BFMatcher to find matches\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /home/conda/feedstock_root/build_artifacts/libopencv_1734356343879/work/modules/features2d/src/sift.dispatch.cpp:512: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'detectAndCompute'\n"
     ]
    }
   ],
   "source": [
    "aligned = process_stack(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holotomocupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
